#!/usr/bin/env node

/**
 * Script to identify and create redirects for old sitemap URLs that return 404s
 * This prevents crawl budget waste and maintains SEO continuity
 */

import fs from 'fs';
import path from 'path';

console.log('ðŸ” Analyzing old sitemap URL patterns that may cause 404s...\n');

const publicDir = 'public';

// Check for existence of old format sitemaps that may be referenced
const oldFormatPatterns = [
  'sitemap.xml',
  'sitemap_index.xml', 
  'sitemap-index.xml'
];

console.log('ðŸ“„ Checking for existing sitemap files:');

oldFormatPatterns.forEach(filename => {
  const filepath = path.join(publicDir, filename);
  if (fs.existsSync(filepath)) {
    console.log(`   âœ… Found: ${filename}`);
  } else {
    console.log(`   âŒ Missing: ${filename} (potential 404)`);
  }
});

// Check for old format individual sitemaps referenced in robots.txt
console.log('\nðŸ¤– Checking robots.txt references:');
const robotsPath = path.join(publicDir, 'robots.txt');
if (fs.existsSync(robotsPath)) {
  const robotsContent = fs.readFileSync(robotsPath, 'utf8');
  const sitemapLines = robotsContent.split('\n').filter(line => line.startsWith('Sitemap:'));
  
  sitemapLines.forEach(line => {
    const url = line.replace('Sitemap:', '').trim();
    const filename = url.split('/').pop();
    const filepath = path.join(publicDir, filename);
    
    if (fs.existsSync(filepath)) {
      console.log(`   âœ… ${url} â†’ File exists`);
    } else {
      console.log(`   âŒ ${url} â†’ File missing (404 error)`);
    }
  });
}

// The old URL format mentioned in robots.txt comments
console.log('\nðŸ”— Checking old URL format from robots.txt comments:');
console.log('   âŒ /sitemap/{start}/{end}.xml â†’ This format no longer exists');
console.log('   âœ… /sitemap-{start}-{end}.xml â†’ New format exists');

console.log('\nðŸ’¡ Recommended fixes:');
console.log('1. Create sitemap.xml as main sitemap index');
console.log('2. Update robots.txt to reference correct sitemap URLs');
console.log('3. Optionally create redirects for old sitemap URL patterns');

// Create a main sitemap.xml that references all sitemap-index files
console.log('\nðŸ› ï¸  Creating main sitemap.xml...');

const sitemapIndexFiles = fs.readdirSync(publicDir)
  .filter(file => file.match(/^sitemap-index-\d+\.xml$/))
  .sort((a, b) => {
    const numA = parseInt(a.match(/\d+/)[0]);
    const numB = parseInt(b.match(/\d+/)[0]);
    return numA - numB;
  });

let mainSitemapContent = '<?xml version="1.0" encoding="UTF-8"?>\n';
mainSitemapContent += '<sitemapindex xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n';

sitemapIndexFiles.forEach(file => {
  const lastmod = new Date().toISOString();
  mainSitemapContent += `  <sitemap>\n`;
  mainSitemapContent += `    <loc>https://skywardparts.com/${file}</loc>\n`;
  mainSitemapContent += `    <lastmod>${lastmod}</lastmod>\n`;
  mainSitemapContent += `  </sitemap>\n`;
});

mainSitemapContent += '</sitemapindex>\n';

// Write the main sitemap.xml
fs.writeFileSync(path.join(publicDir, 'sitemap.xml'), mainSitemapContent);
console.log(`âœ… Created sitemap.xml referencing ${sitemapIndexFiles.length} sitemap-index files`);

console.log('\nâœ¨ Next steps:');
console.log('1. Update robots.txt to reference the new sitemap.xml');
console.log('2. Test that all referenced sitemaps return 200 status');
console.log('3. Resubmit updated sitemap.xml to Google Search Console');